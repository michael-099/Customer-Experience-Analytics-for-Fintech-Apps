{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3b21cb8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\micha\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import spacy\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import re\n",
    "from transformers import pipeline\n",
    "import uuid\n",
    "\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1340be31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\micha\\anaconda3\\Lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\micha\\anaconda3\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "sentiment_pipeline = pipeline(\"sentiment-analysis\", model=\"distilbert-base-uncased-finetuned-sst-2-english\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a34a139e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"scraped data.csv\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7bd0c796",
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews = df[\"review\"].tolist()\n",
    "results = sentiment_pipeline(reviews, truncation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "01a77af4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_score(label, score):\n",
    "    if label == \"POSITIVE\":\n",
    "        return score\n",
    "    elif label == \"NEGATIVE\":\n",
    "        return -score\n",
    "    else:\n",
    "        return 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ccd79f6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_scores = []\n",
    "for result in results:\n",
    "    score = to_score(result[\"label\"], result[\"score\"])\n",
    "    sentiment_scores.append(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "adaababd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"sentiment_score\"] = sentiment_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e3b04b44",
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_df = df.groupby([\"bank\", \"rating\"])[\"sentiment_score\"].mean().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8dd9d309",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   bank  rating  sentiment_score\n",
      "0   BOA       1        -0.779004\n",
      "1   BOA       2        -0.718548\n",
      "2   BOA       3        -0.191240\n",
      "3   BOA       4         0.023577\n",
      "4   BOA       5         0.517518\n",
      "5   CBE       1        -0.603236\n",
      "6   CBE       2        -0.423547\n",
      "7   CBE       3        -0.494413\n",
      "8   CBE       4        -0.066724\n",
      "9   CBE       5         0.712700\n",
      "10   DB       1        -0.884815\n",
      "11   DB       2        -0.726466\n",
      "12   DB       3        -0.091441\n",
      "13   DB       4         0.021889\n",
      "14   DB       5         0.789882\n"
     ]
    }
   ],
   "source": [
    "# agg_df.to_csv(\"aggregated_sentiment.csv\", index=False)\n",
    "print(agg_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "13891008",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"sentiment_label\"] = df[\"sentiment_score\"].apply(\n",
    "    lambda x: \"Positive\" if x > 0 else \"Negative\" if x < 0 else \"Neutral\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f6c2ca6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'review_id' not in df.columns:\n",
    "    df['review_id'] = [str(uuid.uuid4()) for _ in range(len(df))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0535c768",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "96cb3cf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    if not isinstance(text, str):\n",
    "        text = str(text)\n",
    "    # Lowercase\n",
    "    text = text.lower()\n",
    "    # Remove special characters\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)\n",
    "    # Tokenize and remove stopwords\n",
    "    doc = nlp(text)\n",
    "    tokens = [token.lemma_ for token in doc if token.text not in stop_words and not token.is_punct]\n",
    "    return ' '.join(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "be0e2625",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_keywords_spacy(text):\n",
    "    doc = nlp(text)\n",
    "    keywords = []\n",
    "    # Extract nouns, adjectives, and n-grams\n",
    "    for token in doc:\n",
    "        if token.pos_ in ['NOUN', 'ADJ'] and token.text not in stop_words:\n",
    "            keywords.append(token.lemma_)\n",
    "    # Extract noun chunks as n-grams\n",
    "    for chunk in doc.noun_chunks:\n",
    "        if len(chunk.text.split()) > 1:\n",
    "            keywords.append(chunk.text.lower())\n",
    "    return keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee25331e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_keywords_tfidf(reviews):\n",
    "    vectorizer = TfidfVectorizer(max_features=100, ngram_range=(1, 2), stop_words='english')\n",
    "    tfidf_matrix = vectorizer.fit_transform(reviews)\n",
    "    feature_names = vectorizer.get_feature_names_out()\n",
    "    return feature_names.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cc7de1cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cluster_themes(keywords, bank):\n",
    "    theme_dict = {\n",
    "        'Account Access Issues': ['login', 'crash', 'error', 'access', 'authentication', 'sign in', 'log in'],\n",
    "        'Transaction Performance': ['transfer', 'slow', 'fast', 'payment', 'transaction', 'deposit', 'withdrawal'],\n",
    "        'User Interface & Experience': ['ui', 'interface', 'design', 'navigation', 'experience', 'layout', 'user friendly'],\n",
    "        'Customer Support': ['support', 'help', 'service', 'response', 'customer', 'assistance'],\n",
    "        'Feature Requests': ['feature', 'tool', 'budget', 'option', 'functionality', 'add', 'new']\n",
    "    }\n",
    "    themes = []\n",
    "    for keyword in keywords:\n",
    "        for theme, theme_keywords in theme_dict.items():\n",
    "            if any(kw in keyword.lower() for kw in theme_keywords):\n",
    "                themes.append(theme)\n",
    "                break\n",
    "    return list(set(themes)) if themes else ['Other']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e4562ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def thematic_analysis_pipeline(df):\n",
    "    # Preprocess reviews\n",
    "    df['processed_review'] = df['review'].apply(preprocess_text)\n",
    "    \n",
    "    # Extract keywords\n",
    "    df['keywords_spacy'] = df['processed_review'].apply(extract_keywords_spacy)\n",
    "    \n",
    "    # TF-IDF keywords per bank\n",
    "    for bank in df['bank'].unique():\n",
    "        bank_reviews = df[df['bank'] == bank]['processed_review']\n",
    "        tfidf_keywords = extract_keywords_tfidf(bank_reviews)\n",
    "        print(f\"TF-IDF Keywords for {bank}: {tfidf_keywords[:10]}\")  # Print top 10 for reference\n",
    "    \n",
    "    # Cluster into themes\n",
    "    df['themes'] = df.apply(lambda row: cluster_themes(row['keywords_spacy'], row['bank']), axis=1)\n",
    "    \n",
    "    # Prepare output\n",
    "    output_df = df[['review_id', 'review', 'sentiment_label', 'sentiment_score', 'themes']]\n",
    "    \n",
    "    # Save to CSV\n",
    "    output_df.to_csv('thematic_analysis_output.csv', index=False)\n",
    "    print(\"Results saved to 'thematic_analysis_output.csv'\")\n",
    "    \n",
    "    \n",
    "    return output_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e3815491",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF Keywords for CBE: ['access', 'account', 'add', 'amazing', 'app', 'application', 'bad', 'bank', 'banking', 'banking app']\n",
      "TF-IDF Keywords for BOA: ['app', 'app work', 'application', 'ask', 'bad', 'bad app', 'bank', 'banking', 'banking app', 'boa']\n",
      "TF-IDF Keywords for DB: ['account', 'ahead', 'amazing', 'app', 'application', 'bank', 'bank super', 'banking', 'convenient', 'customer']\n",
      "Results saved to 'thematic_analysis_output.csv'\n"
     ]
    }
   ],
   "source": [
    "result_df = thematic_analysis_pipeline(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b5977180",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample Output:\n",
      "                                              review sentiment_label   themes\n",
      "0       the app is proactive and a good connections.        Positive  [Other]\n",
      "1    I cannot send to cbebirr app. through this app.        Negative  [Other]\n",
      "2                                               good        Positive  [Other]\n",
      "3                                     not functional        Negative  [Other]\n",
      "4  everytime you uninstall the app you have to re...        Negative  [Other]\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nSample Output:\")\n",
    "print(result_df[['review', 'sentiment_label', 'themes']].head())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (Stock_Market_Prediction  )",
   "language": "python",
   "name": "stock_market_prediction"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
